{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57de02c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy.interpolate import interpn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "from monai.metrics import DiceMetric\n",
    "from models import CycleTransMorph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b9c86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/mnt/hot/public/4DCT_datasets/DIR-Lab/all\"\n",
    "MODEL_PATH = \"./model_runs/ctm_run_1/best_model.pth\" \n",
    "IMG_SIZE = (128, 128, 128)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dir_lab_case(mat_path):\n",
    "    \"\"\"\n",
    "    Loads image, mask, and landmark data from a single .mat file.\n",
    "    \n",
    "    *** ASSUMPTION ***\n",
    "    This function ASSUMES the following key names inside your .mat file:\n",
    "    - 'image_T00': Inhale (moving) image (Z, Y, X)\n",
    "    - 'image_T50': Exhale (fixed) image (Z, Y, X)\n",
    "    - 'mask_T00': Inhale (moving) mask (Z, Y, X)\n",
    "    - 'mask_T50': Exhale (fixed) mask (Z, Y, X)\n",
    "    - 'landmarks_T00': Inhale landmarks (N, 3) in (x, y, z) mm\n",
    "    - 'landmarks_T50': Exhale landmarks (N, 3) in (x, y, z) mm\n",
    "    - 'spacing': Voxel spacing (3,) in (x_mm, y_mm, z_mm)\n",
    "    - 'original_size': Original image size (3,) in (Z, Y, X)\n",
    "    \n",
    "    You MUST adapt these keys if your .mat files are structured differently.\n",
    "    \"\"\"\n",
    "    data = sio.loadmat(mat_path)\n",
    "    \n",
    "    print(f\"\\nLoading {os.path.basename(mat_path)}. Found keys: {list(data.keys())}\")\n",
    "    \n",
    "    try:\n",
    "        inhale_img = data['T00'].astype(np.float32)\n",
    "        exhale_img = data['T50'].astype(np.float32)\n",
    "        inhale_mask = data['mask_T00'].astype(np.float32)\n",
    "        exhale_mask = data['mask_T50'].astype(np.float32)\n",
    "        \n",
    "        inhale_lms = data['landmarks_T00'].astype(np.float32)\n",
    "        exhale_lms = data['landmarks_T50'].astype(np.float32)\n",
    "        \n",
    "        spacing_xyz = data['spacing'].squeeze().astype(np.float32)\n",
    "        original_size_zyx = data['original_size'].squeeze().astype(np.int32)\n",
    "        \n",
    "        # Normalize images\n",
    "        inhale_img = (inhale_img - np.min(inhale_img)) / (np.max(inhale_img) - np.min(inhale_img))\n",
    "        exhale_img = (exhale_img - np.min(exhale_img)) / (np.max(exhale_img) - np.min(exhale_img))\n",
    "\n",
    "        return {\n",
    "            \"inhale_image\": inhale_img,\n",
    "            \"exhale_image\": exhale_img,\n",
    "            \"inhale_mask\": inhale_mask,\n",
    "            \"exhale_mask\": exhale_mask,\n",
    "            \"inhale_landmarks\": inhale_lms,\n",
    "            \"exhale_landmarks\": exhale_lms,\n",
    "            \"spacing_xyz\": spacing_xyz, # (sx, sy, sz)\n",
    "            \"original_size_zyx\": original_size_zyx # (oz, oy, ox)\n",
    "        }\n",
    "    \n",
    "    except KeyError as e:\n",
    "        print(f\"\\n--- FATAL ERROR ---\")\n",
    "        print(f\"Could not find key {e} in {mat_path}.\")\n",
    "        print(f\"Please edit Cell 5 to match your .mat file structure.\")\n",
    "        print(f\"Available keys are: {list(data.keys())}\")\n",
    "        print(\"---------------------\\n\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0b2d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(np_img, target_size):\n",
    "    \"\"\"\n",
    "    Prepares a numpy image for the model (resize and add batch/channel dims).\n",
    "    \"\"\"\n",
    "    img_tensor = torch.from_numpy(np_img).unsqueeze(0).unsqueeze(0) # (1, 1, D, H, W)\n",
    "    # Resize using F.interpolate (must be 5D for 3D data)\n",
    "    resized_tensor = F.interpolate(img_tensor, size=target_size, mode='trilinear', align_corners=False)\n",
    "    return resized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34436e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_landmarks_dvf(landmarks_xyz, dvf_np_zyx, spacing_xyz, original_size_zyx, target_size_zyx):\n",
    "    \"\"\"\n",
    "    Warps a list of landmarks (in mm) using the predicted DVF.\n",
    "    \n",
    "    Args:\n",
    "        landmarks_xyz: (N, 3) numpy array of landmarks in (x, y, z) PHYSICAL (mm) coordinates.\n",
    "        dvf_np_zyx: (3, D, H, W) numpy array (e.g., 3x128x128x128) from the model.\n",
    "                      The values are displacements in RESIZED VOXEL space.\n",
    "                      Channels are (disp_z, disp_y, disp_x).\n",
    "        spacing_xyz: (3,) numpy array of voxel spacing (sx, sy, sz) in mm.\n",
    "        original_size_zyx: (3,) numpy array of original image size (oz, oy, ox).\n",
    "        target_size_zyx: (3,) tuple of model's image size (tz, ty, tx).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get component DVF fields\n",
    "    dvf_z, dvf_y, dvf_x = dvf_np_zyx[0], dvf_np_zyx[1], dvf_np_zyx[2]\n",
    "    \n",
    "    # Create interpolation grids (for the 128^3 DVF)\n",
    "    grid_z = np.arange(target_size_zyx[0])\n",
    "    grid_y = np.arange(target_size_zyx[1])\n",
    "    grid_x = np.arange(target_size_zyx[2])\n",
    "    \n",
    "    # Get physical size (mm) / target size (voxels)\n",
    "    # This gives us (mm / resized_voxel)\n",
    "    oz, oy, ox = original_size_zyx\n",
    "    tz, ty, tx = target_size_zyx\n",
    "    sx, sy, sz = spacing_xyz\n",
    "    \n",
    "    scale_x = (ox * sx) / tx \n",
    "    scale_y = (oy * sy) / ty\n",
    "    scale_z = (oz * sz) / tz\n",
    "    \n",
    "    warped_landmarks = []\n",
    "    \n",
    "    for (lx, ly, lz) in landmarks_xyz:\n",
    "        # 1. Convert landmark (mm) to original voxel coords\n",
    "        orig_vx = lx / sx\n",
    "        orig_vy = ly / sy\n",
    "        orig_vz = lz / sz\n",
    "        \n",
    "        # 2. Convert original voxel coords to resized (128) voxel coords (query point)\n",
    "        query_x = orig_vx * (tx - 1) / (ox - 1)\n",
    "        query_y = orig_vy * (ty - 1) / (oy - 1)\n",
    "        query_z = orig_vz * (tz - 1) / (oz - 1)\n",
    "        query_point_zyx = (query_z, query_y, query_x)\n",
    "        \n",
    "        # 3. Interpolate displacement vector (in resized voxel units)\n",
    "        disp_z = interpn((grid_z, grid_y, grid_x), dvf_z, query_point_zyx, method='linear', bounds_error=False, fill_value=0)\n",
    "        disp_y = interpn((grid_z, grid_y, grid_x), dvf_y, query_point_zyx, method='linear', bounds_error=False, fill_value=0)\n",
    "        disp_x = interpn((grid_z, grid_y, grid_x), dvf_x, query_point_zyx, method='linear', bounds_error=False, fill_value=0)\n",
    "        \n",
    "        # 4. Convert displacement vector from (resized_voxel) to (mm)\n",
    "        disp_mm_x = disp_x * scale_x\n",
    "        disp_mm_y = disp_y * scale_y\n",
    "        disp_mm_z = disp_z * scale_z\n",
    "        disp_vector_mm = np.array([disp_mm_x, disp_mm_y, disp_mm_z])\n",
    "        \n",
    "        # 5. Add mm displacement to original mm landmark\n",
    "        warped_lm_mm = np.array([lx, ly, lz]) + disp_vector_mm\n",
    "        warped_landmarks.append(warped_lm_mm)\n",
    "        \n",
    "    return np.array(warped_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4182a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jacobian_determinant(dvf_numpy):\n",
    "    \"\"\"\n",
    "    Calculates the 3D Jacobian determinant of the transformation T(p) = p + DVF(p).\n",
    "    DVF shape is (3, D, H, W) with channels (disp_z, disp_y, disp_x).\n",
    "    \"\"\"\n",
    "    \n",
    "    # DVF components\n",
    "    dvf_z = dvf_numpy[0]\n",
    "    dvf_y = dvf_numpy[1]\n",
    "    dvf_x = dvf_numpy[2]\n",
    "    \n",
    "    # Get gradients for each component\n",
    "    # np.gradient returns (grad_z, grad_y, grad_x)\n",
    "    grad_ux = np.gradient(dvf_x) \n",
    "    dux_dz, dux_dy, dux_dx = grad_ux[0], grad_ux[1], grad_ux[2]\n",
    "    \n",
    "    grad_uy = np.gradient(dvf_y)\n",
    "    duy_dz, duy_dy, duy_dx = grad_uy[0], grad_uy[1], grad_uy[2]\n",
    "\n",
    "    grad_uz = np.gradient(dvf_z)\n",
    "    duz_dz, duz_dy, duz_dx = grad_uz[0], grad_uz[1], grad_uz[2]\n",
    "    \n",
    "    # Build Jacobian determinant\n",
    "    # J = I + grad(DVF)\n",
    "    J_11 = 1 + dux_dx\n",
    "    J_12 = dux_dy\n",
    "    J_13 = dux_dz\n",
    "    \n",
    "    J_21 = duy_dx\n",
    "    J_22 = 1 + duy_dy\n",
    "    J_23 = duy_dz\n",
    "    \n",
    "    J_31 = duz_dx\n",
    "    J_32 = duz_dy\n",
    "    J_33 = 1 + duz_dz\n",
    "    \n",
    "    # Compute determinant\n",
    "    det = J_11 * (J_22 * J_33 - J_23 * J_32) \\\n",
    "        - J_12 * (J_21 * J_33 - J_23 * J_31) \\\n",
    "        + J_13 * (J_21 * J_32 - J_22 * J_31)\n",
    "        \n",
    "    return det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e4557c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144548/4077653216.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "model = CycleTransMorph(img_size=IMG_SIZE).to(DEVICE)\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "except FileNotFoundError:\n",
    "    print(f\"--- FATAL ERROR: Model file not found ---\")\n",
    "    print(f\"Could not find model at: {MODEL_PATH}\")\n",
    "    print(f\"Please update the MODEL_PATH variable in Cell 3.\")\n",
    "    raise\n",
    "\n",
    "model.eval()\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5708cacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 cases. Starting evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b426275dca294390b631cd91a60a1e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing DIR-Lab Cases:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading case1.mat. Found keys: ['__header__', '__version__', '__globals__', 'T00', 'T10', 'T20', 'T30', 'T40', 'T50', 'T60', 'T70', 'T80', 'T90']\n",
      "\n",
      "--- FATAL ERROR ---\n",
      "Could not find key 'image_T00' in /mnt/hot/public/4DCT_datasets/DIR-Lab/all/case1.mat.\n",
      "Please edit Cell 5 to match your .mat file structure.\n",
      "Available keys are: ['__header__', '__version__', '__globals__', 'T00', 'T10', 'T20', 'T30', 'T40', 'T50', 'T60', 'T70', 'T80', 'T90']\n",
      "---------------------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'image_T00'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m case_path \u001b[38;5;129;01min\u001b[39;00m tqdm(case_files, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing DIR-Lab Cases\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m# 1. Load Data\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mload_dir_lab_case\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcase_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;66;03m# 2. Preprocess images and masks\u001b[39;00m\n\u001b[1;32m     20\u001b[0m         inhale_tensor \u001b[38;5;241m=\u001b[39m preprocess_image(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minhale_image\u001b[39m\u001b[38;5;124m'\u001b[39m], IMG_SIZE)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "Cell \u001b[0;32mIn[10], line 25\u001b[0m, in \u001b[0;36mload_dir_lab_case\u001b[0;34m(mat_path)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# --- !! ADAPT THESE KEYS !! ---\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     inhale_img \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage_T00\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     26\u001b[0m     exhale_img \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_T50\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     27\u001b[0m     inhale_mask \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask_T00\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image_T00'"
     ]
    }
   ],
   "source": [
    "all_tre_errors = []\n",
    "all_non_positive_jac = []\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean_batch\")\n",
    "\n",
    "case_files = sorted(glob.glob(os.path.join(DATA_DIR, 'case*.mat')))\n",
    "\n",
    "if not case_files:\n",
    "    print(f\"--- FATAL ERROR: No .mat files found ---\")\n",
    "    print(f\"Could not find any 'case*.mat' files in: {DATA_DIR}\")\n",
    "    print(f\"Please update the DATA_DIR variable in Cell 3.\")\n",
    "else:\n",
    "    print(f\"Found {len(case_files)} cases. Starting evaluation...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for case_path in tqdm(case_files, desc=\"Processing DIR-Lab Cases\"):\n",
    "            # 1. Load Data\n",
    "            data = load_dir_lab_case(case_path)\n",
    "            \n",
    "            # 2. Preprocess images and masks\n",
    "            inhale_tensor = preprocess_image(data['inhale_image'], IMG_SIZE).to(DEVICE)\n",
    "            exhale_tensor = preprocess_image(data['exhale_image'], IMG_SIZE).to(DEVICE)\n",
    "            inhale_mask_tensor = preprocess_image(data['inhale_mask'], IMG_SIZE).to(DEVICE)\n",
    "            exhale_mask_tensor = preprocess_image(data['exhale_mask'], IMG_SIZE).to(DEVICE)\n",
    "            \n",
    "            # 3. Run Model (Inhale -> Exhale)\n",
    "            warped_inhale, dvf, svf = model(inhale_tensor, exhale_tensor)\n",
    "            dvf_np = dvf.squeeze(0).cpu().numpy()\n",
    "            \n",
    "            # 4. Calculate TRE\n",
    "            warped_lms = warp_landmarks_dvf(\n",
    "                data['inhale_landmarks'],\n",
    "                dvf_np,\n",
    "                data['spacing_xyz'],\n",
    "                data['original_size_zyx'],\n",
    "                IMG_SIZE\n",
    "            )\n",
    "            tre_errors = np.sqrt(np.sum((warped_lms - data['exhale_landmarks']) ** 2, axis=1))\n",
    "            all_tre_errors.extend(tre_errors)\n",
    "            \n",
    "            # 5. Calculate Jacobian\n",
    "            jacobian_det = get_jacobian_determinant(dvf_np)\n",
    "            all_non_positive_jac.append(np.sum(jacobian_det <= 0) / np.prod(jacobian_det.shape))\n",
    "            \n",
    "            # 6. Calculate DSC\n",
    "            # Warp the inhale mask to the exhale space\n",
    "            warped_inhale_mask = model.spatial_transformer(inhale_mask_tensor, dvf)\n",
    "            \n",
    "            # Binarize masks\n",
    "            warped_mask_binary = (warped_inhale_mask > 0.5).float()\n",
    "            exhale_mask_binary = (exhale_mask_tensor > 0.5).float()\n",
    "            \n",
    "            # Compute dice (MONAI expects one-hot, but binary (B,C,D,H,W) is fine)\n",
    "            dice_metric(y_pred=warped_mask_binary, y=exhale_mask_binary)\n",
    "\n",
    "    print(\"\\nEvaluation loop complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab91ec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_tre_errors:\n",
    "    mean_tre = np.mean(all_tre_errors)\n",
    "    std_tre = np.std(all_tre_errors)\n",
    "    print(f\"--- Target Registration Error (TRE) ---\")\n",
    "    print(f\"Mean TRE:   {mean_tre:.4f} mm\")\n",
    "    print(f\"Std TRE:    {std_tre:.4f} mm\")\n",
    "    print(f\"(SOTA Target: < 1.5 mm)\")\n",
    "else:\n",
    "    print(\"TRE calculation failed. Check data loading.\")\n",
    "\n",
    "if all_non_positive_jac:\n",
    "    mean_jac = np.mean(all_non_positive_jac) * 100\n",
    "    print(f\"\\n--- Jacobian Plausibility ---\")\n",
    "    print(f\"Mean % Non-Positive Jacobians: {mean_jac:.6f} %\")\n",
    "    print(f\"(Target: < 0.1 %)\")\n",
    "else:\n",
    "    print(\"Jacobian calculation failed.\")\n",
    "\n",
    "try:\n",
    "    mean_dice = dice_metric.aggregate().item()\n",
    "    print(f\"\\n--- Dice Similarity Coefficient (DSC) ---\")\n",
    "    print(f\"Mean DSC:   {mean_dice:.4f}\")\n",
    "    print(f\"(Target: > 0.95)\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nDice calculation failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exhale_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
