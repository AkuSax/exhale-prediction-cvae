{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ab3242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from monai.metrics import DiceMetric\n",
    "from models import CycleTransMorph, SpatialTransformer\n",
    "\n",
    "BASE_PATH = \"/mnt/hot/public/Akul/exhale_pred_data\"\n",
    "INSP_PATH = os.path.join(BASE_PATH, \"inhale\")\n",
    "EXP_PATH = os.path.join(BASE_PATH, \"exhale\")\n",
    "INSP_MASK_PATH = os.path.join(BASE_PATH, \"masks\", \"inhale\")\n",
    "EXP_MASK_PATH = os.path.join(BASE_PATH, \"masks\", \"exhale\")\n",
    "MODEL_PATH = \"./experiments/CTM/best_model.pth\"\n",
    "\n",
    "IMG_SIZE = (160, 192, 128) \n",
    "BATCH_SIZE = 1\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93951c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total processed samples: 8702\n",
      "Using 871 samples for testing (10% validation set).\n"
     ]
    }
   ],
   "source": [
    "class LungDataset(Dataset):\n",
    "    def __init__(self, file_paths):\n",
    "        self.file_paths = file_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        paths = self.file_paths[idx]\n",
    "        return {\n",
    "            'insp': torch.from_numpy(np.load(paths['insp'])).float().unsqueeze(0),\n",
    "            'exp': torch.from_numpy(np.load(paths['exp'])).float().unsqueeze(0),\n",
    "            'insp_mask': torch.from_numpy(np.load(paths['insp_mask'])).float().unsqueeze(0),\n",
    "            'exp_mask': torch.from_numpy(np.load(paths['exp_mask'])).float().unsqueeze(0)\n",
    "        }\n",
    "\n",
    "patient_ids = [os.path.basename(p).replace('.npy', '') for p in glob.glob(os.path.join(INSP_PATH, \"*.npy\"))]\n",
    "patient_ids.sort()\n",
    "all_files = [{'insp': os.path.join(INSP_PATH, f\"{pid}.npy\"), 'exp': os.path.join(EXP_PATH, f\"{pid}.npy\"), 'insp_mask': os.path.join(INSP_MASK_PATH, f\"{pid}_INSP_mask.npy\"), 'exp_mask': os.path.join(EXP_MASK_PATH, f\"{pid}_EXP_mask.npy\")} for pid in patient_ids]\n",
    "\n",
    "split_idx = int(0.9 * len(all_files))\n",
    "val_files = all_files[split_idx:]\n",
    "\n",
    "test_dataset = LungDataset(val_files)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Total processed samples: {len(all_files)}\")\n",
    "print(f\"Using {len(test_dataset)} samples for testing (10% validation set).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e582e6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3409216/2996876077.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n"
     ]
    }
   ],
   "source": [
    "model = CycleTransMorph(img_size=IMG_SIZE).to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE, weights_only=True))\n",
    "model.eval()\n",
    "transformer = SpatialTransformer(size=IMG_SIZE).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45ac1b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inhale_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_dataloader):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;66;03m# ... (rest of the dice score loop)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m         warped_mask_img, dvf_i_e, _ \u001b[38;5;241m=\u001b[39m model(\u001b[43minhale_mask\u001b[49m\u001b[38;5;241m.\u001b[39mfloat(), exhale_mask\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m      7\u001b[0m         pred_exhale_mask_binary \u001b[38;5;241m=\u001b[39m (warped_mask_img \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m      8\u001b[0m         dice_metric(y_pred\u001b[38;5;241m=\u001b[39mpred_exhale_mask_binary, y\u001b[38;5;241m=\u001b[39mexhale_mask)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inhale_mask' is not defined"
     ]
    }
   ],
   "source": [
    "from monai.metrics import DiceMetric\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_dataloader):\n",
    "        # ... (rest of the dice score loop)\n",
    "        warped_mask_img, dvf_i_e, _ = model(inhale_mask.float(), exhale_mask.float())\n",
    "        pred_exhale_mask_binary = (warped_mask_img > 0.5).float()\n",
    "        dice_metric(y_pred=pred_exhale_mask_binary, y=exhale_mask)\n",
    "mean_dice = dice_metric.aggregate().item()\n",
    "print(f\"Average Dice Score: {mean_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205794ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PSNR/MAE for sample 1/871...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (192) must match the size of tensor b (128) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m exhale_img \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexhale_img\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Predict the DVF\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m dvf_i_e, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minhale_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexhale_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Warp the inhale image to get the predicted exhale image\u001b[39;00m\n\u001b[1;32m     14\u001b[0m pred_exhale_img \u001b[38;5;241m=\u001b[39m transformer(inhale_img, dvf_i_e)\n",
      "File \u001b[0;32m~/anaconda3/envs/exhale_pred/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/exhale_pred/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Akul/exhale_pred/models.py:70\u001b[0m, in \u001b[0;36mCycleTransMorph.forward\u001b[0;34m(self, moving, fixed)\u001b[0m\n\u001b[1;32m     68\u001b[0m transformer_features \u001b[38;5;241m=\u001b[39m transformer_features\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     69\u001b[0m svf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msvf_head(transformer_features)\n\u001b[0;32m---> 70\u001b[0m dvf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffeomorphic_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msvf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m warped_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspatial_transformer(moving, dvf)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m warped_image, dvf, svf\n",
      "File \u001b[0;32m~/anaconda3/envs/exhale_pred/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/exhale_pred/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Akul/exhale_pred/models.py:26\u001b[0m, in \u001b[0;36mScalingAndSquaring.forward\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m     24\u001b[0m v \u001b[38;5;241m=\u001b[39m v \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling_steps)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling_steps):\n\u001b[0;32m---> 26\u001b[0m     v \u001b[38;5;241m=\u001b[39m v \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m v\n",
      "File \u001b[0;32m~/Akul/exhale_pred/models.py:31\u001b[0m, in \u001b[0;36mScalingAndSquaring.compose\u001b[0;34m(self, v1, v2)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompose\u001b[39m(\u001b[38;5;28mself\u001b[39m, v1, v2):\n\u001b[1;32m     30\u001b[0m     grid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(v1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(v1\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 31\u001b[0m     sampling_grid \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mv1\u001b[49m\n\u001b[1;32m     32\u001b[0m     size \u001b[38;5;241m=\u001b[39m v1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(size):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (192) must match the size of tensor b (128) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "psnr_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_dataloader):\n",
    "        print(f\"Processing PSNR/MAE for sample {i+1}/{len(test_dataloader)}...\")\n",
    "        inhale_img = batch['inhale_img'].to(DEVICE)\n",
    "        exhale_img = batch['exhale_img'].to(DEVICE)\n",
    "\n",
    "        # Predict the DVF\n",
    "        dvf_i_e, _ = model(inhale_img, exhale_img)\n",
    "        \n",
    "        # Warp the inhale image to get the predicted exhale image\n",
    "        pred_exhale_img = transformer(inhale_img, dvf_i_e)\n",
    "\n",
    "        # Move tensors to CPU and convert to numpy for skimage metrics\n",
    "        pred_np = pred_exhale_img.squeeze().cpu().numpy()\n",
    "        gt_np = exhale_img.squeeze().cpu().numpy()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        data_range = gt_np.max() - gt_np.min()\n",
    "        psnr_scores.append(psnr(gt_np, pred_np, data_range=data_range))\n",
    "        mae_scores.append(mae(gt_np, pred_np))\n",
    "\n",
    "avg_psnr = np.mean(psnr_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(f\"  Average PSNR: {avg_psnr:.4f} dB\")\n",
    "print(f\"  Average MAE: {avg_mae:.4f}\")\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bedbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jacobian_determinant(dvf):\n",
    "    \"\"\"\n",
    "    Calculates the Jacobian determinant of a 3D deformation vector field.\n",
    "    DVF shape: (batch, 3, H, W, D)\n",
    "    \"\"\"\n",
    "    # Permute to (H, W, D, 3) for np.gradient\n",
    "    dvf_numpy = dvf.squeeze().permute(1, 2, 3, 0).cpu().numpy()\n",
    "    \n",
    "    # Get gradients of each displacement component\n",
    "    grad_x_du = np.gradient(dvf_numpy[..., 0], axis=0)\n",
    "    grad_y_dv = np.gradient(dvf_numpy[..., 1], axis=1)\n",
    "    grad_z_dw = np.gradient(dvf_numpy[..., 2], axis=2)\n",
    "\n",
    "    # Construct the Jacobian matrix.\n",
    "    J = np.zeros(dvf_numpy.shape + (3,))\n",
    "    J[..., 0, 0] = 1 + grad_x_du\n",
    "    J[..., 0, 1] = np.gradient(dvf_numpy[..., 0], axis=1)\n",
    "    J[..., 0, 2] = np.gradient(dvf_numpy[..., 0], axis=2)\n",
    "\n",
    "    J[..., 1, 0] = np.gradient(dvf_numpy[..., 1], axis=0)\n",
    "    J[..., 1, 1] = 1 + grad_y_dv\n",
    "    J[..., 1, 2] = np.gradient(dvf_numpy[..., 1], axis=2)\n",
    "\n",
    "    J[..., 2, 0] = np.gradient(dvf_numpy[..., 2], axis=0)\n",
    "    J[..., 2, 1] = np.gradient(dvf_numpy[..., 2], axis=1)\n",
    "    J[..., 2, 2] = 1 + grad_z_dw\n",
    "\n",
    "    return np.linalg.det(J)\n",
    "\n",
    "non_positive_jacobians = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_dataloader):\n",
    "        print(f\"Processing Jacobian for sample {i+1}/{len(test_dataloader)}...\")\n",
    "        inhale_img = batch['inhale_img'].to(DEVICE)\n",
    "        exhale_img = batch['exhale_img'].to(DEVICE)\n",
    "\n",
    "        # Predict the DVF\n",
    "        dvf_i_e, _ = model(inhale_img, exhale_img)\n",
    "        \n",
    "        # Calculate Jacobian determinant\n",
    "        jacobian_det = get_jacobian_determinant(dvf_i_e)\n",
    "        \n",
    "        # Count non-positive values\n",
    "        num_non_positive = np.sum(jacobian_det <= 0)\n",
    "        total_voxels = np.prod(jacobian_det.shape)\n",
    "        \n",
    "        percentage = (num_non_positive / total_voxels) * 100\n",
    "        non_positive_jacobians.append(percentage)\n",
    "\n",
    "avg_non_positive = np.mean(non_positive_jacobians)\n",
    "\n",
    "print(\"\\n\" + \"=\"*55)\n",
    "print(f\"  Average Percentage of Non-Positive Jacobian Values: {avg_non_positive:.6f}%\")\n",
    "print(\"=\"*55)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exhale_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
